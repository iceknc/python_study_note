# -*- coding: utf-8 -*-
# @Author: 徐志鹏
# @Date  : 2019/7/23
# @Desc  : 
"""
通用爬虫和聚焦爬虫
    根据使用场景，网络爬虫可分为 通用爬虫 和 聚焦爬虫 两种

通用爬虫
    通用网络爬虫 是 捜索引擎抓取系统（Baidu、Google、Yahoo等）的重要组成部分。
    主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份

通用搜索引擎（Search Engine）工作原理
    通用网络爬虫 从互联网中搜集网页，采集信息，这些网页信息用于为搜索引擎建立索引从而提供支持，
    它决定着整个引擎系统的内容是否丰富，信息是否即时，因此其性能的优劣直接影响着搜索引擎的效果

聚焦爬虫
    聚焦爬虫，是"面向特定主题需求"的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于：
    聚焦爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息
"""

def main():
    encode = u"个人普通小汽车摇号指标配置结果".encode()
    print(type(encode))
    for i in range(len(encode)):
        print(encode[i])


if __name__ == "__main__":
    main()
    






